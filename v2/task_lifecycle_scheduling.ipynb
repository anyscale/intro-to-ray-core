{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b752be-c1a2-428b-be5c-bcd3fbaeaf50",
   "metadata": {},
   "source": [
    "# Distributed Scheduling Deep-dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9065e725-7bb2-4fe9-8a54-78dc1f52eee5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ray Cluster overview\n",
    "\n",
    "A Ray cluster consits of:\n",
    "- One or more **woker nodes**, where each worker node consists of the following processes:\n",
    "    - **worker processes** responsible for task submission and execution. Each worker process stores:\n",
    "        - An **ownership table**: System metadata for the objects to which the worker has a reference, e.g., to store ref counts and object locations\n",
    "        - An **in-process store**: used to store small objects (<100KB)\n",
    "    - A **raylet**: Manages shared resources on each node. The raylet has two main components:\n",
    "        - A **scheduler**: Responsible for resource management, task placement, and fulfilling task arguments that are stored in the distributed object store. The individual schedulers in a cluster comprise **the Ray distributed scheduler**.\n",
    "        - A **shared-memory object store** (also known as the **Plasma Object Store**). Responsible for storing, transferring, and spilling **large objects**. The individual object stores in a cluster comprise the **Ray distributed object store**.\n",
    "- One of the worker nodes is designated as a **head node** which is a special node that also hosts\n",
    "  - A **global control service**: keeps track of the **cluster state** that is not supposed to change often\n",
    "  - **Cluster level services**: are services that are shared across the cluster suc as autoscaling, job submission, etc. \n",
    "  - A **driver**: a special worker process that executes the top-level application. It can submit tasks but does not execute them.\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/ray_cluster.png\" width=\"800\">\n",
    "\n",
    "\n",
    "Note that \n",
    "- The **plasma object store** by default is in-memory and takes up **30% of the memory of the node**\n",
    "- If the **plasma object store** is full, objects are **spilled to disk**\n",
    "\n",
    "<!-- \n",
    "Reference: \n",
    "- See [V2 architecture document -> Architecture Overview -> Design -> Components](https://docs.google.com/document/d/1tBw9A4j62ruI5omIJbMxly-la5w4q_TjyJgJL_jN2fI/preview#heading=h.cclei73t0j5p)\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21758807-b7ab-4460-8464-758220161447",
   "metadata": {},
   "source": [
    "## Scheduling a Task\n",
    "\n",
    "Below is a high-level diagram showing the primary stages in scheduling a task leading to its execution. \n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_high_level.svg\" width=\"1400px\">\n",
    "\n",
    "Note that the diagram presents a simplified ordering of the steps invovled. Also note that while it shows certain steps being launched from a worker or a raylet, those steps are run in separate processes as we will detail later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2ee56-449e-40dd-8b10-fe99ff0ee1a5",
   "metadata": {},
   "source": [
    "### Stage 1: Serializing Function Code\n",
    "\n",
    "When a Ray task is first called, its definition is pickled and then stored in the GCS.\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_serialization.svg\" width=\"600px\">\n",
    "\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. [Python .remote calls ._remote](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L140)\n",
    "    2. [Python ._remote pickles the function](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L299)\n",
    "    3. [Python ._remote call exports the function via the function manager.export](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_private/function_manager.py#L273)\n",
    "    4. [Which calls the cython GcsClient.internal_kv_put](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L2579)\n",
    "    5. [Which calls the gcs_client.cc PythonGcsClient::InternalKVPut](https://github.com/ray-project/ray/blob/55ab6dfd6b415f8795dd1dfed7b3fde2558efc46/src/ray/gcs/gcs_client/gcs_client.cc#L312) that sets the key, value in the proper namespace -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c3ad2-37ec-4578-b24f-8422dcc94dea",
   "metadata": {},
   "source": [
    "### Stage 2: Claiming ownership\n",
    "\n",
    "Ownership is claimed by following these steps:\n",
    "- The core worker process will request from its task manager to add the pending task\n",
    "- The task manager will create an object reference for the returned result\n",
    "- The core worker will request from its reference counter to update its ownership table with the created object reference\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_ownership_claim.svg\" width=\"600px\">\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. [Python .remote calls ._remote](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L140)\n",
    "    2. [python ._remote call calls submit_task](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L420)\n",
    "    3. [submit_task calls the cython submit_task function defined here](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3574)\n",
    "    4. [cython submit_task Delegates to C++ CoreWorker::SubmitTask]((https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3643)\n",
    "    5. [CoreWorker::SubmitTask in turn calls TaskManager::AddPendingTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L1944)\n",
    "    6. [TaskManager::AddPendingTask assigns a return id for referencing the task result](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/task_manager.cc#L195]\n",
    "    7. [TaskManager::AddPendingTask calls ReferenceCounter::AddOwnedObject to claim ownership of task result](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/task_manager.cc#L207)\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c33592-b0c8-41da-98b1-10167654ca79",
   "metadata": {},
   "source": [
    "### Stage 3: Resolving Task Dependencies\n",
    "\n",
    "Given a particular task `Task` that depends on:\n",
    "- object `A` as input\n",
    "- object `B` as input\n",
    "\n",
    "The core worker's submitter process will perform these steps\n",
    "\n",
    "1. Find each dependency's owner:\n",
    "    - Inspect the object reference to object `A` to find its owner address (IP + port)\n",
    "    - Inspect the object reference to object `B` to find its owner address (IP + port)\n",
    "2. Fetch metadata from the owner's ownership table about each object\n",
    "    - Request metadata about object `A` (e.g. the size and location of the of the object)\n",
    "    - Request metadata about object `B` (e.g. the size and location of the of the object)\n",
    "3. Proceed with scheduling now that all dependencies are resolved\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_resolving_deps.svg\" width=\"600px\">\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. [Python .remote calls ._remote](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L140)\n",
    "    2. [python ._remote call calls submit_task](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L420)\n",
    "    3. [submit_task calls the cython submit_task function defined here](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3574)\n",
    "    4. [cython submit_task Delegates to C++ CoreWorker::SubmitTask]((https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3643)\n",
    "    5. [CoreWorker::SubmitTask calls direct_task_submitter.SubmitTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L1949)\n",
    "    5. [direct_task_submitter.SubmitTask calls ResolveDependencies to resolve dependencies](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L28)\n",
    "    6. [ResolveDependencies calls InlineDependencies](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/dependency_resolver.cc#L117)\n",
    "    7. [InlineDependencies fetches task metadata like the size](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/dependency_resolver.cc#L44C10-L44C10)\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fd54b7-7647-46bd-a8e4-cbbdc16b9f4d",
   "metadata": {},
   "source": [
    "### Stage 4: Enforcing data locality\n",
    "\n",
    "The core worker's submitter process will choose the raylet on the node that has the most number of object argument bytes already local to schedule the task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed1749-21e2-47f0-bc71-cbdab818684c",
   "metadata": {},
   "source": [
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_data_locality.svg\" width=\"800px\">\n",
    "\n",
    "Note: this stage is skipped in case the task's specified scheduling policy is stringent (e.g. a node-affinity policy)\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. [Python .remote calls ._remote](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L140)\n",
    "    2. [python ._remote call calls submit_task](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L420)\n",
    "    3. [submit_task calls the cython submit_task function](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3643)\n",
    "    4. [cython submit_task Delegates to SubmitTask from c++ Core Worker with calls direct_task_submitter.SubmitTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L1949)\n",
    "    5. [direct_task_submitter.SubmitTask calls ResolveDependencies to resolve dependencies](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L28)\n",
    "    6. [direct_task_submitter.SubmitTask as a callback will now call RequestNewWorkerIfNeeded](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L135)\n",
    "    7. [RequestNewWorkerIfNeeded will in turn call GetBestNodeForTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L394)\n",
    "    8. [GetBestNodeForTask will pick a node for locality in case the scheduling strategy is not stringent (i.e. node affinity or spread)](https://github.com/ray-project/ray/blob/master/src/ray/core_worker/lease_policy.cc#L39)\n",
    "    9. [GetBestNodeIdForTask will find the node with the most object bytes](https://github.com/ray-project/ray/blob/master/src/ray/core_worker/lease_policy.cc#L47C1-L48C1) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d6fc2-ee57-46b0-ba48-8dd1ee529c08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Stage 5: Applying Scheduling Policy\n",
    "\n",
    "The selected \"Scheduler Raylet\" will undergo these steps to locate the best node to execute the task\n",
    "\n",
    "- It receives updates from the GCS every 100ms\n",
    "    - The updates contain metadata about the resources on each node\n",
    "- It determines which nodes/raylets are feasible for scheduling given the task resource requirements\n",
    "- It will then apply the task's scheduling policy\n",
    "- The policy will determine the node/raylet that will be executing the task (i.e. our \"executor raylet\")\n",
    "\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_applying_policy.svg\" width=\"600px\">\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. Add task to task queue:\n",
    "        1. [Python .remote calls ._remote](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L140)\n",
    "        2. [python ._remote call calls submit_task](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/remote_function.py#L420)\n",
    "        3. [submit_task calls the cython submit_task function](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3643)\n",
    "        4. [cython submit_task Delegates to SubmitTask from c++ Core Worker with calls direct_task_submitter.SubmitTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L1949)\n",
    "        5. [direct_task_submitter.SubmitTask calls ResolveDependencies to resolve dependencies](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L28)\n",
    "        6. [direct_task_submitter.SubmitTask will now schedule the task onto the task queue](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L113)\n",
    "    2. Raylet's scheduler picks up task from task queue and applies scheduling policy\n",
    "        3. [A raylet when instantiated is composed of a node manager](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/raylet.h#L96)\n",
    "        4. A node manager is composed of:\n",
    "            - A cluster task manager which is responsible for queuing, spilling back, and dispatching tasks.\n",
    "            - A cluster resource scheduler is responsible for maintaining a view of the cluster state w.r.t resource usage.\n",
    "            - [These two classes make up the distributed scheduler](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/node_manager.h#L819)\n",
    "        5. [direct_task_submitter.SubmitTask as a callback will now call RequestNewWorkerIfNeeded](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L135)\n",
    "        6. [RequestNewWorkerIfNeeded will in turn call RequestWorkerLease](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/transport/direct_task_transport.cc#L405)\n",
    "        6. [When a worker lease request comes in a raylet's NodeManager::HandleRequestWorkerLease gets call](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/node_manager.cc#L1783)\n",
    "        7. [NodeManager::HandleRequestWorkerLease will delegate a call to ClusterTaskManager::QueueAndScheduleTask()](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/node_manager.cc#L1830)\n",
    "        8. [ClusterTaskManager::QueueAndScheduleTask it will delegate a call to ClusterTaskManager::ScheduleAndDispatchTasks()](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/cluster_task_manager.cc#L64)\n",
    "        9. [ScheduleAndDispatchTasks will call ClusterResourceManager::GetBestSchedulableNode() taking into account the schedulding strategy set on the task specification](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/cluster_task_manager.cc#L148C14-L155C1) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7ce746-8f30-479e-a7a3-764400be2866",
   "metadata": {},
   "source": [
    "### Stage 6: Leasing a worker\n",
    "\n",
    "The executor raylet will perform these steps for each task in its queue\n",
    "- It will try to ensure a fair distribution of tasks amongst different scheduling policies\n",
    "- It will wait for the tasks arguments to be available\n",
    "- It will check if the node can allocate resources for the task\n",
    "- It will now secure a worker and respond with the worker address to the owner process\n",
    "\n",
    "If it fails to any of the checks, it will try to:\n",
    "- wait and retry the steps\n",
    "- re-apply the scheduling policy to check if it can spill the task to another node that is now better suited\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_leasing_worker.svg\" width=\"1000px\">\n",
    "\n",
    "Notes: \n",
    "- After this stage, the owner process will now own the lease to the worker\n",
    "- The lease remains active as long as the owner process and leased worker are alive, and the raylet ensures that no other client may use the worker while the lease is active.\n",
    "- The owner may schedule any number of tasks onto the leased worker, as long as the tasks are compatible with the granted resource request. Hence, leases can be thought of as an optimization to avoid communication with the scheduler for similar scheduling requests.\n",
    "\n",
    "\n",
    "<!-- References:\n",
    "- See code:\n",
    "    1. [When a worker lease request comes in a raylet's NodeManager::HandleRequestWorkerLease gets call](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/node_manager.cc#L1783)\n",
    "    2. [NodeManager::HandleRequestWorkerLease will delegate a call to ClusterTaskManager::QueueAndScheduleTask()](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/node_manager.cc#L1830)\n",
    "    3. [ClusterTaskManager::QueueAndScheduleTask it will delegate a call to ClusterTaskManager::ScheduleAndDispatchTasks()](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/cluster_task_manager.cc#L64)\n",
    "    4. [ClusterTaskManager.ScheduleAndDispatchTasks() will call LocalTaskManager::ScheduleAndDispatchTasks()](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/cluster_task_manager.cc#L227)\n",
    "    5. [LocalTaskManager::ScheduleAndDispatchTasks() will call LocalTaskManager::DispatchScheduledTasksToWorkers()](https://github.com/ray-project/ray/blob/master/src/ray/raylet/local_task_manager.cc#L96)\n",
    "    6. [LocalTaskManager::DispatchScheduledTasksToWorkers() will secure a worker for a task in the call to WorkPool.PopWorker() only after securing that owner is active, arguments are available, resources are allocated)](https://github.com/ray-project/ray/blob/master/src/ray/raylet/local_task_manager.cc#L267)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf77f07-e97c-4a49-853d-9b6aebb5a743",
   "metadata": {},
   "source": [
    "### Stage 7: Executing the task\n",
    "\n",
    "Once a worker receives a task it will perform these steps:\n",
    "\n",
    "- Consume the task from the queue\n",
    "- Prepare the function for execution\n",
    "- Submit the RayFunction to a task execution callback that will\n",
    "    - Deserialize the function arguments\n",
    "    - Construct and execute the python function within cython (dealing with async functions)\n",
    "    - Handle results properly:\n",
    "        - Perform error handling extracting error information if there is a failure\n",
    "        - Deal with generator results\n",
    "    - Prepare the return object\n",
    "        - Seal the return object\n",
    "        - Update the reference counts\n",
    "        - Run garbage collection:\n",
    "            - if \"borrowed\" dependency objects are no longer needed, they will be deleted from the object store\n",
    "        - If the return object(s) are small\n",
    "            - Return the values inline directly to the owner, which copies them to its in-process object store.\n",
    "        - If the return object(s) are large\n",
    "            - Store the objects in the node's shared memory store and reply to  owner indicating the objects are now in distributed memory.\n",
    "- Return the final status of the task execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dadf2b-c39d-40c0-a649-3f12d2ac0879",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_execution.svg\" width=\"1200px\">\n",
    "\n",
    "\n",
    "<!-- References: \n",
    "- See code:\n",
    "    1. [When instantiating a CoreWorker, we add task receivers which will callback CoreWorker::ExecuteTask](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L147)\n",
    "    2. [CoreWorker::ExecuteTask() will prepare a RayFunction and submit it to its execution callback](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/core_worker/core_worker.cc#L2721C21-L2721C44)\n",
    "    3. [The task execution callback in the case of python will execute the function from cython given the set task_execution_handler](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L3075C43-L3075C65)\n",
    "    4. [The task execution handler will execute the task with a cancellation handler](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L2064C17-L2064C55)\n",
    "    5. [The handler will call execute_task handling a KeyboardInterrupt error](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L1960C7-L1960C7)\n",
    "    6. [execute_task will invoke the function_executor](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L1675)\n",
    "    7. [execute_task will store the outputs in the object store](https://github.com/ray-project/ray/blob/releases/2.8.1/python/ray/_raylet.pyx#L1810C12-L1810C12) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bebdb9-23bf-4f5c-b75c-7dddb5a139b1",
   "metadata": {},
   "source": [
    "### Stage 8: Fetching the task result\n",
    "\n",
    "Here are the steps in fetching a task's result, i.e. when ray.get gets called\n",
    "\n",
    "1. find the owner using the object reference\n",
    "2. the owner will look up its ownership table to find where in distributed memory the object is located\n",
    "3. the owner will fetch the object and return it\n",
    "4. the owner will update the reference count to the object\n",
    "5. the owner will trigger grabage collection if the reference count is now 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b01e6-ab1f-45ae-ab14-50734fbccf22",
   "metadata": {},
   "source": [
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_fetching.svg\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d18be57-14d8-4ac8-bc97-9dd2103f5b83",
   "metadata": {},
   "source": [
    "# Overview of Scheduling Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946813d-9312-4e63-9872-7d9c9e14bc96",
   "metadata": {},
   "source": [
    "Ray provides different scheduling strategies that you can set on your task.\n",
    "\n",
    "We will go over:\n",
    "- How a raylet assess feasibility and availability of nodes\n",
    "- How every scheduling strategy works and when you should use it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee7a35-f5d1-428d-a3e1-a66c4407fb98",
   "metadata": {},
   "source": [
    "## How does a raylet classify nodes as feasible/infeasible and available/unavailable?\n",
    "\n",
    "Given a resource requirement, a raylet will determine if a node is\n",
    "- feasible vs infeasible node \n",
    "- for feasible nodes, the raylet determine if the node is:\n",
    "    - available or not available\n",
    "\n",
    "The raylet will make use of the resource updates that it receives by broadcast from GCS every 100ms to make these decisions.\n",
    "\n",
    "Let's understand this by looking at this example task `Task`, that has a resource requirement of 3 CPUs:\n",
    "- all nodes with >= 3 CPUs are classified as **feasible**, otherwise infeasible\n",
    "    - for those nodes that have >= 3 CPUs **idle**, they are classified as **available**, otherwise not available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3774958c-07fa-4e62-be46-54a18ddd0fc1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Task</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Node</th>\n",
       "      <th>Raylet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Resource Requirements</th>\n",
       "      <th>Resource Capacity</th>\n",
       "      <th>Status</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_cpus=3</td>\n",
       "      <td>4 CPUs</td>\n",
       "      <td>Idle node</td>\n",
       "      <td>Feasible and Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_cpus=3</td>\n",
       "      <td>4 CPUs</td>\n",
       "      <td>2 CPUs tied up running another task</td>\n",
       "      <td>Feasible but Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>num_cpus=3</td>\n",
       "      <td>2CPUs</td>\n",
       "      <td>Idle node</td>\n",
       "      <td>Infeasible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Task              Node  \\\n",
       "  Resource Requirements Resource Capacity   \n",
       "0            num_cpus=3            4 CPUs   \n",
       "1            num_cpus=3            4 CPUs   \n",
       "2            num_cpus=3             2CPUs   \n",
       "\n",
       "                                                            Raylet  \n",
       "                                Status              Classification  \n",
       "0                            Idle node      Feasible and Available  \n",
       "1  2 CPUs tied up running another task  Feasible but Not Available  \n",
       "2                            Idle node                  Infeasible  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read DataFrame from CSV\n",
    "pd.read_csv(\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/raylet_node_classification.csv\", header=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9755b82f-b86d-4e47-ac4f-5c9238dca42c",
   "metadata": {},
   "source": [
    "## Default Scheduling Strategy\n",
    "\n",
    "### How does it work?\n",
    "This is the default policy used by ray. It is a hybrid policy that combines the following two heuristics:\n",
    "- Bin packing heuristic\n",
    "- Load balancing heuristic\n",
    "\n",
    "### Use-cases\n",
    "- Works well as a default: it usually results in data locality being honored.\n",
    "\n",
    "<!-- ### References:\n",
    "- See code here:\n",
    "    - [Default Hybrid Scheduling Policy is defined here](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/policy/hybrid_scheduling_policy.cc) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa50e575-7810-4762-92c5-ba307c64f1bb",
   "metadata": {},
   "source": [
    "The diagram below shows the policy in action in a bin-packing heuristic/mode\n",
    "\n",
    "Note the **Local Node** shown in the diagram is the node that is local to the raylet that received the worker lease request - which in almost all cases is the raylet that satisfies data locality requirements.\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_policy_hybrid_policy_binpacking.svg\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ed34d-1d44-4b58-bbd0-3641f7c365cd",
   "metadata": {},
   "source": [
    "The diagram below shows the policy in action in a load balancing heuristic. \n",
    "\n",
    "This occurs when our preferred local node is heavily being utilized. The strategy will now spread new tasks amongst other feasible and available nodes.\n",
    "\n",
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_policy_hybrid_policy_balancing.svg\" width=\"900px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1358afc-669c-4ea7-a873-e5747fbec9a2",
   "metadata": {},
   "source": [
    "## Node Affinity Strategy\n",
    "\n",
    "### How does it work?\n",
    "It assigns a task to a given node in either a strict or soft manner.\n",
    "\n",
    "### Use-cases\n",
    "- When you want to ensure that your task runs on a specific node: e.g. you want to make sure a given accelerator is used for a compute-intensive task.\n",
    "\n",
    "\n",
    "<!-- ### References:\n",
    "- See code here\n",
    "    - [Node Affinity Policy is defined here](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/policy/node_affinity_scheduling_policy.cc)\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e958ad-4d1f-4513-be26-524b9d3e7958",
   "metadata": {},
   "source": [
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_policy_node_affinity.svg\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66136a5-980f-455c-b97a-28e29597a49a",
   "metadata": {},
   "source": [
    "### Sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61371ae5-ffa8-48a0-b4e0-be5378c7874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:03:45,916\tINFO worker.py:1633 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray.util.scheduling_strategies import NodeAffinitySchedulingStrategy\n",
    "\n",
    "\n",
    "@ray.remote(\n",
    "    scheduling_strategy=NodeAffinitySchedulingStrategy(\n",
    "        node_id=ray.get_runtime_context().get_node_id(),\n",
    "        soft=False,\n",
    "    )\n",
    ")\n",
    "def node_affinity_schedule():\n",
    "    return 2\n",
    "\n",
    "\n",
    "ray.get(node_affinity_schedule.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d5f03-2742-45e0-9939-e4300c98e748",
   "metadata": {},
   "source": [
    "## SPREAD Scheduling Strategy\n",
    "\n",
    "### How does it work?\n",
    "It behaves like a best-effort round-robin. It spreads across all the available nodes first and then the feasible nodes.\n",
    "\n",
    "### Use-cases\n",
    "- When you want to load-balance your tasks across nodes. e.g. you are building a web service and want to avoid overloading certain nodes.\n",
    "\n",
    "\n",
    "<!-- ### References:\n",
    "- See code here\n",
    "    - [Spread Scheduling Policy is defined here](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/policy/spread_scheduling_policy.cc)\n",
    "  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c1a5e4-2aae-462d-b4c3-f71280568ec5",
   "metadata": {},
   "source": [
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_policy_spread.svg\" width=\"700px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbf117-865f-4b6f-88f6-6c9671ffa172",
   "metadata": {},
   "source": [
    "### Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1610bdc8-ab5e-4de4-9a03-12f6609a0687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "\n",
    "@ray.remote(scheduling_strategy=\"SPREAD\")\n",
    "def spread_default_func():\n",
    "    return 2\n",
    "\n",
    "\n",
    "ray.get(spread_default_func.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbf3515-9c48-42a3-a61f-83d722dc7aee",
   "metadata": {},
   "source": [
    "## Placement Group Scheduling Strategy\n",
    "\n",
    "In cases when we want to treat a set of resources as a single unit, we can use placement groups.\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "- A **placement group** is formed from a set of **resource bundles**\n",
    "  - A **resource bundle** is a list of resource requirements that fit in a single node\n",
    "- A **placement group** can specify a **placement strategy** that determines how the **resource bundles** are placed\n",
    "  - The **placement strategy** can be one of the following:\n",
    "    - **PACK**: pack the **resource bundles** into as few nodes as possible\n",
    "    - **SPREAD**: spread the **resource bundles** across as many nodes as possible\n",
    "    - **STRICT_PACK**: pack the **resource bundles** into as few nodes as possible and fail if not possible\n",
    "    - **STRICT_SPREAD**: spread the **resource bundles** across as many nodes as possible and fail if not possible\n",
    "- **Placement Groups** are **atomic** \n",
    "  -  i.e. either all the **resource bundles** are placed or none are placed\n",
    "  -  GCS uses a two-phase commit protocol to ensure atomicity\n",
    "\n",
    "### Use-cases\n",
    "- Use SPREAD when you want to load-balance your tasks across nodes. e.g. you are building a web service and want to avoid overloading certain nodes.\n",
    "- Use PACK when you want to maximize resource utilization. e.g. you are running training and want to cut costs by packing all your resource bundles on a small subset of nodes.\n",
    "\n",
    "<!-- ### References\n",
    "- [See code here for Bundle Scheduling Policy](https://github.com/ray-project/ray/blob/releases/2.8.1/src/ray/raylet/scheduling/policy/bundle_scheduling_policy.cc) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86af99-9c06-4a9c-b73b-0c9f1d1cbe94",
   "metadata": {},
   "source": [
    "<img src=\"https://assets-training.s3.us-west-2.amazonaws.com/ray-core/task-actor-lifecycle/v2/scheduling/scheduling_policy_placement_group.svg\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9553a1dc-a980-42f6-a542-48974140578a",
   "metadata": {},
   "source": [
    "### Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbf1929-0bcc-4abf-a372-e09eea922907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'placement_group_id': '1f68b1aaa61cf3a4130f9bd5ec2c01000000', 'name': 'my_pg', 'bundles': {0: {'CPU': 0.1}}, 'bundles_to_node_id': {0: 'ed50ecd2dcb4443e107b5b0b9da78065e86e8428924fd1ae82c0a780'}, 'strategy': 'PACK', 'state': 'CREATED', 'stats': {'end_to_end_creation_latency_ms': 2.57, 'scheduling_latency_ms': 2.349, 'scheduling_attempt': 1, 'highest_retry_delay_ms': 0.0, 'scheduling_state': 'FINISHED'}}\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray.util.scheduling_strategies import PlacementGroupSchedulingStrategy\n",
    "# Import placement group related functions\n",
    "from ray.util.placement_group import (\n",
    "    placement_group,\n",
    "    placement_group_table,\n",
    "    remove_placement_group,\n",
    ")\n",
    "\n",
    "# Reserve a placement group of 1 bundle that reserves 0.1 CPU\n",
    "pg = placement_group([{\"CPU\": 0.1}], strategy=\"PACK\", name=\"my_pg\")\n",
    "\n",
    "# Wait until placement group is created.\n",
    "ray.get(pg.ready(), timeout=10)\n",
    "\n",
    "# look at placement group states using the table\n",
    "print(placement_group_table(pg))\n",
    "\n",
    "\n",
    "@ray.remote(\n",
    "    scheduling_strategy=PlacementGroupSchedulingStrategy(\n",
    "        placement_group=pg,\n",
    "    ),\n",
    "    # task requirement needs to be less than placement group capacity\n",
    "    num_cpus=0.1,\n",
    ")\n",
    "def placement_group_schedule():\n",
    "    return 2\n",
    "\n",
    "\n",
    "out = ray.get(placement_group_schedule.remote())\n",
    "print(out)\n",
    "\n",
    "# Remove placement group.\n",
    "remove_placement_group(pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619893f8-b458-4e8a-a2de-d438120150db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
