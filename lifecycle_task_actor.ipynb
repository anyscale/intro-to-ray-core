{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of a task\n",
    "\n",
    "We start out detailing the full lifecylce of a task, from when it is created and submitted till when it is completed and the results are returned to the user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import TextWrapper\n",
    "\n",
    "wrapper = TextWrapper(width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure no ray cluster is running\n",
    "# subprocess.run([\"ray\", \"stop\", \"--force\"], check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,000 feet view\n",
    "\n",
    "We have a python function convenitenly named `expensive_computation` which executes an expensive computation. To keep it simple all it does is sleep for a given number of seconds.\n",
    "\n",
    "It gets called in sequence a number of times (`n_runs`) to be specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 30\n",
    "\n",
    "def expensive_computation():\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    return 1\n",
    "\n",
    "results = [expensive_computation() for _ in range(n_runs)]\n",
    "assert sum(results) == n_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the execution visualized\n",
    "\n",
    "<img src=\"sequential_simple_.jpeg\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to:\n",
    "- Run the same function in a distributed fashion - i.e. in parallel on a cluster of machines\n",
    "- Get the results of the function as they become available\n",
    "\n",
    "We do this by following these steps:\n",
    "- Convert the `expensive_computation` function to a ray task decoration by decorating it with `ray.remote`\n",
    "- Submit a task for execution by calling `future = expensive_computation.remote()`\n",
    "- Use the returned `future` object reference to fetch the result of the function by calling `ray.get(future)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 18:36:15,765\tINFO worker.py:1633 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "@ray.remote # decorator to convert function to a ray task\n",
    "def expensive_computation():\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    return 1\n",
    "\n",
    "# submit n_ray tasks to multiple workers in the cluster and keep a reference to the result\n",
    "futures = [expensive_computation.remote() for _ in range(n_runs)] \n",
    "# wait for all tasks to complete and get the resulting objects\n",
    "results = ray.get(futures) \n",
    "# confirm that we got the right result\n",
    "assert sum(results) == n_runs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what is happening under the hood:\n",
    "\n",
    "<img src=\"parallel_simple.jpeg\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000 feet view\n",
    "\n",
    "Let's detail the parallel execution of the function a bit more.\n",
    "\n",
    "More specifically:\n",
    "- ray tasks are executed on a ray cluster as part of a ray job\n",
    "- ray workers are the processes that execute the tasks\n",
    "- futures in ray are called `ObjectRef`s short for object references\n",
    "- results are stored as objects in the ray object store\n",
    "- ray.get() is used to fetch an object given its object reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote # decorator to convert function to a ray task\n",
    "def expensive_computation():\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "    return 1\n",
    "\n",
    "# this returns an object reference to the result\n",
    "object_ref_future = expensive_computation.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(a631fe8d231813bfffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_ref_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for the tasks to complete and get the resulting object\n",
    "object_value = ray.get(object_ref_future) \n",
    "object_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more detailed view of the parallel execution\n",
    "\n",
    "\n",
    "<img src=\"parallel_1000_feet.jpeg\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the ray state client to verify the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.util.state import list_tasks\n",
    "from textwrap import TextWrapper\n",
    "\n",
    "wrapper = TextWrapper(width=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-declare the `expensive_computation` but give it a unique name so we can easily track its state and a longer sleep time so we can see the state evolve more clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'expensive_computation_ac87bc4f'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "task_sleep_time = 20\n",
    "\n",
    "@ray.remote\n",
    "def my_task():\n",
    "    import time\n",
    "\n",
    "    time.sleep(task_sleep_time)\n",
    "    return 1\n",
    "\n",
    "\n",
    "id_ = str(uuid4())[:8]\n",
    "name = f\"expensive_computation_{id_}\"\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.remote_function.RemoteFunction.options.<locals>.FuncWrapper at 0x11d579a30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray_task = my_task.options(name=name)\n",
    "ray_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(79cc316456d39201ffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we submit the task\n",
    "ray_task.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task expensive_computation_ac87bc4f is in state=RUNNING running on worker 2d866cac as part of Job ID 01000000\n",
      "task expensive_computation_ac87bc4f is in state=RUNNING running on worker 2d866cac as part of Job ID 01000000\n",
      "task expensive_computation_ac87bc4f is in state=RUNNING running on worker 2d866cac as part of Job ID 01000000\n",
      "task expensive_computation_ac87bc4f is in state=RUNNING running on worker 2d866cac as part of Job ID 01000000\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "while time.time() - start_time < task_sleep_time:\n",
    "    time.sleep(5)\n",
    "    task = next(task for task in list_tasks() if task.name == name)\n",
    "    print(f\"task {task.name} is in state={task.state} running on worker {task.worker_id[:8]} as part of Job ID {task.job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 feet view\n",
    "\n",
    "Let's further detail the lifecycle of a ray task.\n",
    "\n",
    "More specifically here is what a cluster looks like:\n",
    "\n",
    "\n",
    "<img src=\"ray_cluster_.jpeg\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to keep in mind:\n",
    "\n",
    "- The head node is a special node that runs the driver and the global control service. \n",
    "- The head node can also spawn worker processes to execute tasks\n",
    "- The Global control service keeps track of cluster state that is not supposed to change often\n",
    "- Each worker process will keep track of all the task it executes and submits in its ownership table\n",
    "- Small objects (< 100KB) are stored in the in-process object store of a worker\n",
    "- large objects are stored in the plasma store which is shared across worker processes on the same node\n",
    "- plasma store by default is in-memory and takes up 30% of the memory of the node\n",
    "- if plasma store is full, objects are spilled to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the cluster architecture in mind, let's look at the lifecycle of a task in more detail.\n",
    "\n",
    "<img src=\"parallel_100feet.jpeg\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object management and dependency resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drill down on how a task's dependencies are resolved - using the following example of simple batch inference:\n",
    "\n",
    "- we load a model\n",
    "- we use the model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "\n",
    "def load_model(size_mb):\n",
    "    weights = np.ones((1024, 1024, size_mb), dtype=np.uint8)\n",
    "    assert weights.nbytes / 1024**2 == size_mb\n",
    "    return weights\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def predict(model, input):\n",
    "    return model * input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with this simple implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 1 GB model in memory\n",
    "model = load_model(1_000) \n",
    "\n",
    "# submit 3 tasks to the cluster\n",
    "futures = ray.get([predict.remote(model, i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 `predict` tasks that will be submitted.\n",
    "\n",
    "- The owner of each task will need to go over all the task arguments and:\n",
    "    - check that all the arguments are available\n",
    "    - store a reference to all the available arguments in the (plasma) shared or inprocess object store\n",
    "- In the case of our 1 GB model, the owner will make use of the shared object store given our object is > 1KB\n",
    "- Each owner will create a copy of the model and produce a model reference to use as the argument for the task\n",
    "- Each owner process will now execute their task\n",
    "\n",
    "The outcome is that we have made 3 copies of the model in the shared object store.\n",
    "\n",
    "Instead to save on memory, we should use the `ray.put` API to store the model in the shared object store and pass the reference to the model as an argument to the task.\n",
    "\n",
    "Here is the optimized implementation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the model in the object store and get a reference to it\n",
    "model_ref = ray.put(model)\n",
    "\n",
    "# submit 3 tasks to the cluster using the same model reference\n",
    "futures = ray.get([predict.remote(model_ref, i) for i in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of an Actor\n",
    "\n",
    "An actor is a stateful object that can be used to encapsulate state and methods that operate on that state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,000 feet view\n",
    "\n",
    "Let's take an example of a simple counter actor. We create an actor handle by calling `Counter.remote()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class MyCounter:\n",
    "    def __init__(self) -> None:\n",
    "        self.counter = 0\n",
    "\n",
    "    def increment(self):\n",
    "        time.sleep(3)\n",
    "        self.counter += 1\n",
    "        \n",
    "    def get_counter(self):\n",
    "        return self.counter\n",
    "\n",
    "my_counter_handle = MyCounter.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call methods on the actor handle to increment the counter and get the current value of the counter. The methods will be executed sequentially against the actor process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 6000 MiB, 6 objects, write throughput 3026 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will take 3 seconds * 3 = 9 seconds at least\n",
    "ray.get([my_counter_handle.increment.remote() for _ in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get(my_counter_handle.get_counter.remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a diagram showing the lifecycle of our actor (note that our actor is referred to as a \"synchronous\" actor)\n",
    "\n",
    "\n",
    "<img src=\"actor_simple_.jpeg\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A special \"create actor\" task is executed on the cluster to create the actor process\n",
    "- The actor process can be thought of as a special worker process\n",
    "- The actor tasks are executed sequentially on the actor process using a FIFO queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1,000 feet view of ray actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will detail the lifecycle of an actor in more detail.\n",
    "\n",
    "- Actors are always owned by the GCS (global control service), unlike tasks which are owned by the worker process that submitted them\n",
    "- The GCS maintains an actor table that keeps track of all the actors in the cluster\n",
    "- Actors hold the resources they need to execute their tasks until they are killed\n",
    "- Actors can be launched in a detached mode, in which case they do not fate share with a ray driver/job - instead they need to be killed manually\n",
    "\n",
    "See the below diagram for more details\n",
    "\n",
    "\n",
    "<img src=\"actor_centralized.jpeg\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our actors can be asynchronous - this is especially useful for actors whose methods are IO bound and whose state can be easily shared and locked if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncio import sleep\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "class MyAsyncService:\n",
    "    def __init__(self) -> None:\n",
    "        self.fixed_state = 1\n",
    "\n",
    "    async def run(self):\n",
    "        await sleep(15)\n",
    "        return self.fixed_state\n",
    "\n",
    "\n",
    "my_async_actor_handle = MyAsyncService.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the service run is mostly IO bound (sleeping), we can run it asynchronously using an asynchronous actor implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.get([my_async_actor_handle.run.remote() for _ in range(3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a diagram visualizing task execution against an asynchroneous actor.\n",
    "\n",
    "<img src=\"actor_async.jpeg\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray-core-deep-dive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
